{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "Spark SQL (and its Datasets) allow us to load datasets and build a schema automatically. Let's do this with our NAM dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load('hdfs://orion12:9001/nam/2019/11/*.gz',\n",
    "                     format='csv',\n",
    "                     sep='\\t',\n",
    "                     inferSchema='true',\n",
    "                     header='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many records do we have?\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the data. We can see our schema here:\n",
    "df.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering, SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to get very high temperature values:\n",
    "hot = df.filter(df.temperature_surface > 316)\n",
    "hot.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an SQL 'table'\n",
    "df.createOrReplaceTempView(\"my_table\")\n",
    "\n",
    "# For queries that will return a single result, .take(1) is very useful:\n",
    "spark.sql('SELECT AVG(temperature_surface) FROM my_table').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT MAX(temperature_surface) FROM my_table').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT AVG(relative_humidity_zerodegc_isotherm) FROM my_table WHERE temperature_surface > 318').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidities = spark.sql('SELECT relative_humidity_zerodegc_isotherm FROM my_table WHERE temperature_surface > 318')\n",
    "\n",
    "# Let's say we're going to use the DataSet generated above frequently.\n",
    "# We can cache it here to get better performance for subsequent usages.\n",
    "humidities.cache()\n",
    "humidities.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is probably okay to do here since we only have ~100 values\n",
    "# to collect to the client:\n",
    "local_hum = humidities.collect()\n",
    "\n",
    "# (just be careful not to do it with huge datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in local_hum:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = df.sample(False, .1)\n",
    "print(samp.count())\n",
    "\n",
    "# This will write the sample to '/sampled_output' in HDFS, one for each\n",
    "# worker. You can call samp.coalesce(1) to bring all the data to a single\n",
    "# worker before writing, but performance will suffer.\n",
    "samp.write.csv('hdfs://orion12:9001/sampled_output', sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
