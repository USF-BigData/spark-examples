{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Analysis with Spark\n",
    "\n",
    "We went through this little example as an introduction to Spark. It loads some tweets, filters out lines that don't start with 'W', removes empty tweets, splits them up into words and then locates URIs to determine what the most popular URIs were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = sc.textFile(\"hdfs://orion12:9001/tweets2009-09.txt\")\n",
    "text_file \\\n",
    "    .filter(lambda line: line.startswith('W')) \\\n",
    "    .filter(lambda tweet: tweet != 'W\\tNo Post Title') \\\n",
    "    .flatMap(lambda tweet: tweet.split(\" \")) \\\n",
    "    .filter(lambda word: word.startswith('http')) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .sortBy(lambda x: x[1], False) \\\n",
    "    .take(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 10% sample:\n",
    "text_file = sc.textFile(\"hdfs://orion12:9001/small_tweets.txt\")\n",
    "text_file.sample(False, .1).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
